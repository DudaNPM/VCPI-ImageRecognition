{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_HG2o62RXaar"
      },
      "source": [
        "# Imports and configs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC949FGHrG6P",
        "outputId": "db768361-ea86-4955-8aa2-be21a07db1dc"
      },
      "outputs": [],
      "source": [
        "!pip install perlin-noise\n",
        "!pip install opencv-python\n",
        "!pip install tensorflow_addons\n",
        "!pip3 install git+https://github.com/pvigier/perlin-numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjOM8OsppKay",
        "outputId": "1d1bd446-efd6-4efd-a26a-cb801fde23b3"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as display\n",
        "\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from keras import Model\n",
        "from keras.utils import plot_model\n",
        "from keras.layers import Concatenate, Average\n",
        "from perlin_noise import PerlinNoise\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint,TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Conv2D, MaxPooling2D, Dense, Activation, Flatten, Dropout, Input, Layer\n",
        "from perlin_numpy import (generate_fractal_noise_2d, generate_fractal_noise_3d,generate_perlin_noise_2d, generate_perlin_noise_3d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0cQMQdVrFFX"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 32\n",
        "CLASS_COUNT = 43\n",
        "\n",
        "DATA_DIR = \"/content/gtsrb\"\n",
        "\n",
        "log_and_model_path = '/content/drive/MyDrive/project_logs'\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "normalize = tf.keras.layers.Rescaling(1.0/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW4eqmctXfIj",
        "outputId": "725e5922-4ad8-4e26-e36f-d44caec3cd9e"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrke_hTSrbtU",
        "outputId": "d48caaf2-555d-4017-9cca-93dcd6508d06"
      },
      "outputs": [],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ex7L6BkVj0-"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swscdwWI9Rpu",
        "outputId": "2948ddc9-16d7-4569-d1d5-b34c98444074"
      },
      "outputs": [],
      "source": [
        "!mkdir /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXPe7V088z7J",
        "outputId": "300d4ea5-717f-4964-948e-1c4fc8cc6dc6"
      },
      "outputs": [],
      "source": [
        "\n",
        "!unzip /content/drive/MyDrive/gtsrb.zip -d /content/\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R1knVrr1oJvk"
      },
      "source": [
        "# Convert ppm to png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLBe39UBoMmk"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "def ppm2png(path):\n",
        "    df = None\n",
        "    type = path.split(\"\\\\\")\n",
        "\n",
        "    if (type[-1] == \"test\"):\n",
        "        df = pd.read_csv(path + \"/GT-final_test.test.csv\", \";\")\n",
        "        df.set_index(\"Filename\", inplace=True)\n",
        "\n",
        "    for filepathdir in glob.iglob(path +\"/*/\"):\n",
        "        if(type[-1] == \"train\"):\n",
        "            df = pd.read_csv(filepathdir + \"GT-\" + filepathdir.split(\"\\\\\")[-2] + \".csv\", \";\")\n",
        "            df.set_index(\"Filename\", inplace=True)\n",
        "\n",
        "        for filepath in glob.iglob(filepathdir + \"/*.ppm\"):\n",
        "\n",
        "            im = Image.open(filepath)\n",
        "            row = df.loc[filepath.split(\"\\\\\")[-1]]\n",
        "\n",
        "            if not row.empty:\n",
        "                im = im.crop((row[2],row[3],row[4],row[5]))\n",
        "\n",
        "\n",
        "\n",
        "            filepath2 = os.path.splitext(filepath)[0] + \".png\"\n",
        "            im.save(filepath2)\n",
        "            #os.remove(filepath)\n",
        "\n",
        "ppm2png(\"gtsrb\\\\test\")\n",
        "ppm2png(\"gtsrb\\\\train\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lxsaa0_RXaay"
      },
      "source": [
        "# Auxiliary functions to display images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCFzAKVxXaay"
      },
      "outputs": [],
      "source": [
        "def show_batch(cols, image_batch, label_batch):\n",
        "\n",
        "    rows = int(BATCH_SIZE / cols)\n",
        "    if rows * cols < BATCH_SIZE:\n",
        "        rows += 1\n",
        "    width = 3 * rows\n",
        "    height = 3 * cols\n",
        "\n",
        "\n",
        "    f, axes= plt.subplots(rows,cols,figsize=(height,width))\n",
        "    fig=plt.figure()\n",
        "    for n in range(BATCH_SIZE):\n",
        "\n",
        "        subplot_title=(\"class \"+ classNames[label_batch[n]==1][0])\n",
        "        axes.ravel()[n].set_title(subplot_title)\n",
        "        axes.ravel()[n].imshow(image_batch[n])\n",
        "        axes.ravel()[n].axis('off')\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_history(history):\n",
        "    print(history.history.keys())\n",
        "\n",
        "    # summarize history for accuracy\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='lower right')\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_accuracies():\n",
        "    fig, ax = plt.subplots()\n",
        "    X = np.arange(2)\n",
        "\n",
        "    models = ['bad val set', 'good val set']\n",
        "    plt.bar(X, [evalV1[1], evalV2[1]], width = 0.4, color = 'b', label='test')\n",
        "    plt.bar(X + 0.4, [valV1[1], valV2[1]], color = 'r', width = 0.4, label = \"val\")\n",
        "    plt.xticks(X + 0.4 / 2, models)\n",
        "    plt.ylim(top = 1.0, bottom = 0.70)\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_misclassified(predictions, ground_truth, images, num_rows= 5, num_cols=3):\n",
        "\n",
        "    # Plot the first X test images with wrong predictions.\n",
        "    num_images = num_rows*num_cols\n",
        "    plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "    i = 0\n",
        "    k = 0\n",
        "    while k < len(images) and i < num_images:\n",
        "        predicted_label = np.argmax(predictions[k])\n",
        "        gt = np.where(ground_truth[k])[0][0]\n",
        "        if predicted_label != gt:\n",
        "            plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "            plot_image(k, predictions[k], gt, images)\n",
        "            plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "            plot_value_array(k, predictions[k], ground_truth)\n",
        "            i += 1\n",
        "        k += 1\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label, img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(classNames[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                classNames[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(43))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(CLASS_COUNT), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[np.where(true_label)[0][0]].set_color('blue')\n",
        "\n",
        "def plot_predictions(predictions, ground_truth, images, num_rows= 5, num_cols=3 ):\n",
        "\n",
        "    num_images = num_rows*num_cols\n",
        "    plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "    for i in range(min(num_images,len(images))):\n",
        "        gt = np.where(ground_truth[i])[0][0]\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "        plot_image(i, predictions[i], gt, images)\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "        plot_value_array(i, predictions[i], ground_truth)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_confusion_matrix(model, dataset):\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    for images , labels in dataset.take(-1):\n",
        "        numpy_labels = labels.numpy()\n",
        "        numpy_images = images.numpy()\n",
        "        preds = model.predict(numpy_images, verbose=0)\n",
        "\n",
        "        all_labels += [np.argmax(x) for x in numpy_labels]\n",
        "        all_preds += [np.argmax(x) for x in preds]\n",
        "\n",
        "    conf_mat = tf.math.confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    df_cm = pd.DataFrame(conf_mat.numpy(), range(CLASS_COUNT), range(CLASS_COUNT))\n",
        "    plt.figure(figsize=(15,10))\n",
        "    sn.set(font_scale=1.4) # for label size\n",
        "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='d') # font size\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    res_correct = {}\n",
        "    res_incorrect = {}\n",
        "    for i in range(CLASS_COUNT):\n",
        "      res_correct[i] = 0\n",
        "      res_incorrect[i] = 0\n",
        "\n",
        "    for i in range(len(all_preds)):\n",
        "        if all_preds[i] == all_labels[i]:\n",
        "            res_correct[all_labels[i]] += 1\n",
        "        else:\n",
        "            res_incorrect[all_labels[i]] += 1\n",
        "\n",
        "    for i in range(len(res_correct)):\n",
        "\n",
        "        print('class: ', i, ' total images: ', res_correct[i] + res_incorrect[i],' % correct: ', res_correct[i] / (res_correct[i] + res_incorrect[i]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UFhO0VIPXaa0"
      },
      "source": [
        "# Auxiliary functions to load images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHDQSMYwXaa0"
      },
      "outputs": [],
      "source": [
        "classNames = np.array(['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009',\n",
        "                       '00010', '00011', '00012', '00013', '00014', '00015', '00016', '00017', '00018', '00019',\n",
        "                       '00020', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00029',\n",
        "                       '00030', '00031', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039',\n",
        "                       '00040', '00041', '00042'])\n",
        "\n",
        "\n",
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "\n",
        "  return parts[-2] == classNames\n",
        "\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_png(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "\n",
        "  # resize the image to the desired size.\n",
        "  im_shape = img.shape\n",
        "  img = tf.py_function(call_change_contrast, [img], tf.uint8)\n",
        "  img.set_shape(im_shape)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  img = tf.image.resize(img, [IMAGE_SIZE,IMAGE_SIZE])\n",
        "  return img # tensorflow resize changes dtype to float32 and it doesn't make sense in rgb format\n",
        "\n",
        "\n",
        "def get_bytes_and_label(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label\n",
        "\n",
        "\n",
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "def prepareCallbacks(path):\n",
        "    file_path = f'{log_and_model_path}/{path}/cp.ckpt'\n",
        "\n",
        "    checkpointer = ModelCheckpoint(filepath= file_path,\n",
        "                                monitor = 'val_accuracy',\n",
        "                                verbose=1,\n",
        "                                save_weights_only=True,\n",
        "                                save_best_only=True)\n",
        "\n",
        "\n",
        "    earlyStopper = EarlyStopping(monitor='val_accuracy', min_delta = 0.0001, patience = 15, verbose = 1)\n",
        "    reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.000000001, verbose = 1)\n",
        "\n",
        "    tbCallBack = TensorBoard(log_dir=f'{log_and_model_path}/{path}_log', histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "    return file_path, [checkpointer, earlyStopper, reduceLR, tbCallBack, MyCustomCallback()]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "We-cCyezcWUI"
      },
      "source": [
        "# Auxiliary functions for data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ghalchMcWUI"
      },
      "outputs": [],
      "source": [
        "def process_image(image, label):\n",
        "\n",
        "    # random rotate 5 degrees\n",
        "    r = tf.random.uniform(shape=(), minval=-0.175, maxval=0.175, dtype=tf.dtypes.float32)\n",
        "    image = tfa.image.rotate(image, r)\n",
        "\n",
        "    # translate image up to 10%\n",
        "    rx = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)\n",
        "    ry = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)\n",
        "    image = tfa.image.translate(image, [rx, ry])\n",
        "\n",
        "    # change hue, saturation and value\n",
        "    image = tfa.image.random_hsv_in_yiq(image, 0.2, 0.4, 1.1, 0.4, 1.1)\n",
        "    image = tf.clip_by_value(image,0,255)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def call_change_contrast(img):\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "      lab= cv2.cvtColor(img.numpy(), cv2.COLOR_RGB2LAB)\n",
        "      l_channel, a, b = cv2.split(lab)\n",
        "\n",
        "    # Applying CLAHE to L-channel\n",
        "    # feel free to try different values for the limit and grid size:\n",
        "      clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "      cl = clahe.apply(l_channel)\n",
        "\n",
        "    # merge the CLAHE enhanced L-channel with the a and b channel\n",
        "      limg = cv2.merge((cl,a,b))\n",
        "\n",
        "    # Converting image from LAB Color model to BGR color spcae\n",
        "      enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
        "      enhanced_img = tf.convert_to_tensor(enhanced_img, dtype=tf.uint8)\n",
        "    return enhanced_img\n",
        "\n",
        "\n",
        "def change_contrast(image,label):\n",
        "    im_shape = image.shape\n",
        "    imagen = tf.py_function(call_change_contrast, [image], tf.uint8)\n",
        "    imagen.set_shape(im_shape)\n",
        "    return imagen, label\n",
        "\n",
        "\n",
        "def change_sharpness(img,label):\n",
        "    img = tfa.image.sharpness(img,0.2)\n",
        "    return img,label\n",
        "\n",
        "\n",
        "def process_contrast(img,label):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    contrast = tf.keras.layers.RandomContrast(factor=(0.3,1.3),value_range=(0,1))\n",
        "    img = tf.cast(contrast(img,training=True),tf.float32)\n",
        "    img = tf.clip_by_value(img,0,1)\n",
        "  return img,label\n",
        "\n",
        "\n",
        "def process_hue(img,label):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    hue = tf.image.random_hue(img,0.3)\n",
        "    img = tf.cast(hue,tf.float32)\n",
        "    img = tf.clip_by_value(img,0,1)\n",
        "  return img,label\n",
        "\n",
        "\n",
        "def process_brightness(img,label):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    bright = tf.keras.layers.RandomBrightness(factor=(-0.8,0.8),value_range=(0,1))\n",
        "    img =  bright(img,training=True)\n",
        "    img = tf.clip_by_value(img,0,1)\n",
        "  return img,label\n",
        "\n",
        "\n",
        "def process_saturation(img,label):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    img = tf.image.random_saturation(img,0.5,3)\n",
        "    img = tf.clip_by_value(img,0,1)\n",
        "  return img,label\n",
        "\n",
        "\n",
        "def process_rotation(img,label):\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "      img = tfa.image.rotate(img, tf.random.uniform(shape=(), minval=-0.5 , maxval=0.5))\n",
        "      image = tf.clip_by_value(img,0,1)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def process_zoom(img,label):\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "      rand_zoom = tf.keras.layers.RandomZoom(height_factor=(-0.15,0))\n",
        "      img = rand_zoom(img,training=True)\n",
        "      img = tf.cast(img,tf.float32)\n",
        "      img = tf.clip_by_value(img,0,1)\n",
        "    return img,label\n",
        "\n",
        "\n",
        "def perlin_noise(img):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    noise = generate_perlin_noise_2d((IMAGE_SIZE, IMAGE_SIZE), (16, 16))\n",
        "    noise = cv2.cvtColor(np.uint8(np.round(np.interp(noise,(noise.min(),noise.max()),(0, 255)))),cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    dst = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3) , np.uint8 )\n",
        "    img = tf.image.convert_image_dtype(img, tf.uint8)\n",
        "\n",
        "    cv2.addWeighted (img.numpy(), 0.5, noise, 0.5, 0, dst)\n",
        "    img = tf.image.convert_image_dtype(dst, tf.float32)\n",
        "\n",
        "  return img\n",
        "\n",
        "\n",
        "def apply_perlin(image,label):\n",
        "    im_shape = image.shape\n",
        "    imagen = tf.py_function(perlin_noise, [image], tf.float32)\n",
        "    imagen.set_shape(im_shape)\n",
        "    img = tf.clip_by_value(imagen,0,1)\n",
        "    return img, label\n",
        "\n",
        "\n",
        "def motion_blur(image):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    kernel_size = 8\n",
        "\n",
        "# Create the vertical kernel.\n",
        "    kernel_v = np.zeros((kernel_size, kernel_size))\n",
        "\n",
        "# Create a copy of the same for creating the horizontal kernel.\n",
        "    kernel_h = np.copy(kernel_v)\n",
        "\n",
        "# Fill the middle row with ones.\n",
        "  #kernel_v[:, int((kernel_size - 1)/2)] = np.ones(kernel_size)\n",
        "    kernel_h[int((kernel_size - 1)/2), :] = np.ones(kernel_size)\n",
        "\n",
        "# Normalize.\n",
        "#kernel_v /= kernel_size\n",
        "    kernel_h /= kernel_size\n",
        "\n",
        "# Apply the vertical kernel.\n",
        "    img = cv2.filter2D(image.numpy(), -1, kernel_h)\n",
        "    img = tf.cast(img,tf.float32)\n",
        "  return img\n",
        "\n",
        "\n",
        "def apply_blur(image,label):\n",
        "  im_shape = image.shape\n",
        "  imagen = tf.py_function(motion_blur, [image], tf.float32)\n",
        "  imagen.set_shape(im_shape)\n",
        "  img = tf.clip_by_value(imagen,0,1)\n",
        "  return img, label\n",
        "\n",
        "\n",
        "def process_translate(img,label):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "  # translate image up to 10%\n",
        "    tr = tf.keras.layers.RandomTranslation(height_factor=(-0.3,0.3),width_factor=(-0.3,0.3),fill_mode='constant')\n",
        "    image = tf.cast(tr(img,training=True),tf.float32)\n",
        "    img = tf.clip_by_value(image,0,1)\n",
        "  return img,label\n",
        "\n",
        "\n",
        "def process_shear(image, label):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    image = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.2, maxval=0.2))\n",
        "    sx = tf.random.uniform(shape=(), minval=-0.15, maxval=0.15, dtype=tf.dtypes.float32)\n",
        "    image = tfa.image.transform(image, [1, sx, -sx*32,   0,1,0,  0,0])\n",
        "    image = tf.clip_by_value(image,0,1)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def process_crop(image, label):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    c = tf.random.uniform(shape=(), minval=24, maxval=32, dtype=tf.dtypes.float32)\n",
        "    image = tf.image.random_crop(image, size=[c,c,3])\n",
        "    image = tf.image.resize(image ,size= [32,32])\n",
        "    image = tf.cast(image,tf.float32)\n",
        "    image = tf.clip_by_value(image,0,1)\n",
        "  return image, label\n",
        "\n",
        "\n",
        "def augment_blur(img,label):\n",
        "  img = tfa.image.gaussian_filter2d(img)\n",
        "  return img,label\n",
        "\n",
        "\n",
        "def call_gaussian_laplace(img):\n",
        "  # gray = cv2.cvtColor(img.numpy(), cv2.COLOR_BGR2GRAY)\n",
        "  gaussian = cv2.GaussianBlur(img.numpy(),(11,11),0)\n",
        "  laplace = cv2.Laplacian(gaussian, cv2.CV_64F, ksize=3)\n",
        "  laplace_abs = np.uint(np.absolute(laplace))\n",
        "  return laplace_abs\n",
        "\n",
        "\n",
        "def gaussian_laplace(image,label):\n",
        "    im_shape = image.shape\n",
        "    imagen = tf.py_function(call_gaussian_laplace, [image], tf.uint8)\n",
        "    imagen.set_shape(im_shape)\n",
        "    return imagen, label\n",
        "\n",
        "\n",
        "def perspective_transformation(img):\n",
        "  with tf.device(\"/gpu:0\"):\n",
        "    y,x = img.shape[:2]\n",
        "    src = np.float32([[0,0], [x,0], [x,y], [0,y]])\n",
        "\n",
        "    # source transformation vertices\n",
        "    h = [0, 0, 0, 0]\n",
        "    w = [0, 0, 0, 0]\n",
        "\n",
        "    # choose a random point\n",
        "    v = random.randint(0, 3)\n",
        "    if v == 0 or v == 2:\n",
        "        mult = [-1, 1]\n",
        "    else :\n",
        "        mult = [1, -1]\n",
        "\n",
        "    for i in range (0 , 2) :\n",
        "        # determine new y - coordinate\n",
        "        h[( v + i ) % 4] = round(y * random.uniform(0.05, 0.15))\n",
        "        # determine new x - coordinate\n",
        "        w[( v + i ) % 4] = round(x * random.uniform(0.05, 0.15))\n",
        "\n",
        "    # transforms opposite vertices\n",
        "    h[( v + 3 - i ) % 4] = mult [1] * h [( v + i ) % 4]\n",
        "    w[( v + 3 - i ) % 4] = mult [0] * w [( v + i ) % 4]\n",
        "\n",
        "    dst = np.float32([[w[0], h[0]], [x - w[1], h[1]], [x - w[2], y - h[2]] , [w[3], y - h[3]]])\n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "  return cv2.warpPerspective(img.numpy(), M, (x,y))\n",
        "\n",
        "\n",
        "def process_perspective(image,label):\n",
        "  im_shape = image.shape\n",
        "  imagen = tf.py_function(perspective_transformation, [image], tf.float32)\n",
        "  imagen.set_shape(im_shape)\n",
        "  img = tf.clip_by_value(imagen,0,1)\n",
        "  return img, label\n",
        "\n",
        "\n",
        "def eraser(input_img):\n",
        "      s_l=0.02\n",
        "      s_h=0.4\n",
        "      r_1=0.3\n",
        "      r_2=1/0.3\n",
        "      v_l=0\n",
        "      v_h=1\n",
        "      pixel_level = True\n",
        "      with tf.device(\"/gpu:0\"):\n",
        "        input_img = input_img.numpy()\n",
        "        if input_img.ndim == 3:\n",
        "            img_h, img_w, img_c = input_img.shape\n",
        "        elif input_img.ndim == 2:\n",
        "            img_h, img_w = input_img.shape\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            if input_img.ndim == 3:\n",
        "                c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "            if input_img.ndim == 2:\n",
        "                c = np.random.uniform(v_l, v_h, (h, w))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "\n",
        "def process_erasing(image,label):\n",
        "  # load image to img\n",
        "  im_shape = image.shape\n",
        "  imagen = tf.py_function(eraser, [image], tf.float32)\n",
        "  imagen.set_shape(im_shape)\n",
        "  img = tf.clip_by_value(imagen,0,1)\n",
        "  return img, label\n",
        "\n",
        "\n",
        "def confetti_noise(image, kernel=(0.03, 0.03), probability=0.03, spacing=0.015):\n",
        "  h,w = image.shape[:2]\n",
        "  kh,kw = round(kernel[0] * h), round(kernel[1] * w)\n",
        "  s = round(spacing * min(kernel[0], kernel[1]))\n",
        "  y,x = 0,0\n",
        "\n",
        "  new_image = image.numpy()\n",
        "\n",
        "  for i in range(h - kh):\n",
        "    if y > 0:\n",
        "      y -= 1\n",
        "      continue\n",
        "\n",
        "    for j in range(w - kw + 1):\n",
        "      if x > 0:\n",
        "        x -= 1\n",
        "        continue\n",
        "\n",
        "      if random.random() <= probability:\n",
        "        # insert colored block\n",
        "        new_image[i : i + kh, j : j + kw, :3] = random.uniform(0,1), random.uniform(0,1), random.uniform(0,1)\n",
        "        y,x = kh + s, kw + s\n",
        "\n",
        "  return new_image\n",
        "\n",
        "\n",
        "def process_confetti_noise(image,label):\n",
        "  im_shape = image.shape\n",
        "  imagen = tf.py_function(confetti_noise, [image], tf.float32)\n",
        "  imagen = tf.py_function(perlin_noise, [imagen], tf.float32)\n",
        "  imagen.set_shape(im_shape)\n",
        "  img = tf.clip_by_value(imagen,0,1)\n",
        "  return img, label\n",
        "\n",
        "\n",
        "def process_hlines(image, label):\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "    size_ver = int(tf.random.uniform(shape=(), minval=0, maxval=8, dtype=tf.dtypes.int32)/2)\n",
        "    size_ver = tf.cond(tf.math.equal(size_ver % 2, 1),\n",
        "                        lambda: size_ver + 1,\n",
        "                        lambda: size_ver)\n",
        "    \n",
        "    val = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.dtypes.float32)\n",
        "    return tf.squeeze(tfa.image.random_cutout(image, (size_ver, IMAGE_SIZE), constant_values = val), axis=0), label\n",
        "\n",
        "def process_vlines(image, label):\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "    size_hor = int(tf.random.uniform(shape=(), minval=0, maxval=8, dtype=tf.dtypes.int32)/2)\n",
        "    size_hor = tf.cond(tf.math.equal(size_hor % 2, 1),\n",
        "                        lambda: size_hor + 1,\n",
        "                        lambda: size_hor)\n",
        "    \n",
        "    val = tf.random.uniform(shape=(), minval=0, maxval=1, dtype=tf.dtypes.float32)\n",
        "    return tf.squeeze(tfa.image.random_cutout(image, (IMAGE_SIZE, size_hor), constant_values = val), axis=0), label\n",
        "  \n",
        "\n",
        "def process_image_testing(img,l):\n",
        "  img,l = process_translate(img,l)\n",
        "  img,l = process_rotation(img,l)\n",
        "  img,l = process_shear(img,l)\n",
        "  img,l = process_hue(img,l)\n",
        "  img,l = process_saturation(img,l)\n",
        "  img,l = process_brightness(img,l)\n",
        "  return img,l"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7V-Jd6_FXaa1"
      },
      "source": [
        "# Loading the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucq9idEAXaa1",
        "outputId": "0a038036-3538-476d-a770-68b48f3796de"
      },
      "outputs": [],
      "source": [
        "all_train_listset = tf.data.Dataset.list_files(f'{DATA_DIR}/train/*/*.png')\n",
        "all_train_set = all_train_listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
        "\n",
        "all_train_set = all_train_set.shuffle(buffer_size=39210)\n",
        "train_set = all_train_set.take(int(0.8 * all_train_set.cardinality().numpy()))\n",
        "val_set = all_train_set.skip(int(0.8 * all_train_set.cardinality().numpy()))\n",
        "\n",
        "test_listset = tf.data.Dataset.list_files(f'{DATA_DIR}/test/*/*.png')\n",
        "test_set = test_listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
        "\n",
        "print('All train set size:', all_train_set.cardinality().numpy())\n",
        "print('... train set size:', train_set.cardinality().numpy())\n",
        "print('...   val set size:', val_set.cardinality().numpy())\n",
        "print('...  test set size:', test_set.cardinality().numpy())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r5Z50Du6Xaa2"
      },
      "source": [
        "## Printing Some Images and dataset length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mcVV3hPKkU-v",
        "outputId": "1d11ef37-9190-4982-b472-313079131c6c"
      },
      "outputs": [],
      "source": [
        "for image, label in train_set.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())\n",
        "  plt.imshow(image)\n",
        "  plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SjZx4InJKEwC"
      },
      "source": [
        "# Test Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lkih7XSIKHQf",
        "outputId": "37d7525b-203e-4385-aa01-aa7e33b38bf7"
      },
      "outputs": [],
      "source": [
        "for img, label in train_set.take(10):\n",
        "  # print(\"Image shape: \", img.numpy().shape)\n",
        "  # print(\"Label: \", label.numpy())\n",
        "  # plt.imshow(img)\n",
        "  # plt.show()\n",
        "\n",
        "  # gray = cv2.cvtColor(img.numpy(), cv2.COLOR_BGR2GRAY)\n",
        "  # imgT = cv2.GaussianBlur(gray,(11,11),0)\n",
        "  # laplacian1 = cv2.Laplacian(imgT, cv2.CV_64F, ksize=3)\n",
        "  # laplacian1_abs = np.uint(np.absolute(laplacian1))\n",
        "\n",
        "  # img = tfa.image.translate(img.numpy(), [random.randint(-10,10),random.randint(-10,10)])\n",
        "\n",
        "  # c = tf.random.uniform(shape=(), minval=24, maxval=32, dtype=tf.dtypes.float32)\n",
        "  # img = tf.image.random_crop(img.numpy(), size=[c,c,3])\n",
        "  # img = tf.image.resize(img ,size= [48,48])\n",
        "  # img = tf.cast(img,tf.uint8)\n",
        "\n",
        "  # img,label = apply_blur(img,label)\n",
        "\n",
        "  # img,label = process_image_testing(img,label)\n",
        "\n",
        "  # img = confetti_noise(img)\n",
        "\n",
        "  # img,label = apply_perlin(img,label)\n",
        "\n",
        "  img2,_ = process_erasing(img,label)\n",
        "\n",
        "  # plt.imshow(img)\n",
        "  # plt.imshow(laplacian1_abs, cmap='gray')\n",
        "  # plt.show()\n",
        "\n",
        "  _, axarr = plt.subplots(1,2)\n",
        "  axarr[0].imshow(img)\n",
        "  axarr[1].imshow(img2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n5ef5buDsgDi"
      },
      "source": [
        "# Model I: Using only Convolutional layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ilaNpw3soTt"
      },
      "outputs": [],
      "source": [
        "def model_I(classCount, imgSize, channels):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Input(shape=(imgSize, imgSize, channels)))\n",
        "\n",
        "    model.add(Conv2D(64, (5, 5)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Conv2D(64, (5, 5) ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, (5, 5) ) )\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(classCount, activation='softmax'))\n",
        "\n",
        "\n",
        "    opt = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=[ 'accuracy'])\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PE6fwqPCcWUL"
      },
      "source": [
        "# Model II - Just changing model parameters (more filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnhqRZIHcWUL"
      },
      "outputs": [],
      "source": [
        "def model_II(classCount, imgSize, channels):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(128, (5, 5), input_shape=(imgSize, imgSize, channels)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    model.add(Conv2D(128, (5, 5) ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(256, (5, 5) ) )\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(classCount, activation='softmax'))\n",
        "\n",
        "\n",
        "    opt = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=[ 'accuracy'])\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mMQjmZU4wrC3"
      },
      "source": [
        "# Model III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOBwBbA6wqSW"
      },
      "outputs": [],
      "source": [
        "def model_III(classCount, imgSize, channels):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(100, (5, 5), input_shape=(imgSize, imgSize, channels)))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(150, (5, 5) ))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "    model.add(Conv2D(250, (5, 5) ))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(350))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(classCount, activation='softmax'))\n",
        "\n",
        "\n",
        "    opt = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=[ 'accuracy'])\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UcEZlkdPsCDN"
      },
      "source": [
        "# Dataset 1: no modifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4_bpNoaXaa3"
      },
      "outputs": [],
      "source": [
        "train_set_1 = train_set\n",
        "train_set_1 = train_set_1.cache()\n",
        "train_set_1 = train_set_1.batch(batch_size = BATCH_SIZE)\n",
        "train_set_1 = train_set_1.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_1 = val_set\n",
        "val_set_1 = val_set_1.cache()\n",
        "val_set_1 = val_set_1.batch(batch_size = BATCH_SIZE)\n",
        "val_set_1 = val_set_1.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_1 = test_set\n",
        "test_set_1 = test_set_1.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OLGpQIsXcWUM"
      },
      "source": [
        "# Teste 1: model 1 dataset 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVDbvJGSXaa6",
        "outputId": "04f6b2e8-4564-4207-a82e-fa5b6215e353"
      },
      "outputs": [],
      "source": [
        "model_1_1 = model_I(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_1_1, callbacks_1_1 = prepareCallbacks('best_1_1')\n",
        "\n",
        "history_1_1 = model_1_1.fit(train_set_1,\n",
        "                            epochs=50,\n",
        "                            validation_data = val_set_1,\n",
        "                            callbacks=callbacks_1_1,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkzsLKU7-_wi"
      },
      "outputs": [],
      "source": [
        "show_history(history_1_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYmPPqRCpMXz",
        "outputId": "1da6eb1c-9a7b-48c6-ba48-a3aefc26d6cc"
      },
      "outputs": [],
      "source": [
        "model_1_1.load_weights(file_path_1_1)\n",
        "eval_1_1 = model_1_1.evaluate(test_set_1, verbose=2)\n",
        "print(eval_1_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHrY4T4FD2aN"
      },
      "outputs": [],
      "source": [
        "show_confusion_matrix(model_1_1, test_set_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q1nac5wCD93G",
        "outputId": "6d194acf-7a66-4282-82c3-d17f3de0553d"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_1.take(10):  # take 10 batches of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = model_1_1.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n_8SuRV9bihM"
      },
      "source": [
        "# Teste 2: model 2 dataset 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brvRdVeUbzTa",
        "outputId": "c4e39ce6-00e2-4216-8e04-4e86e4f8a116"
      },
      "outputs": [],
      "source": [
        "model_2_1 = model_II(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_2_1, callbacks_2_1 = prepareCallbacks('best_2_1')\n",
        "\n",
        "history_2_1 = model_2_1.fit(train_set_1,\n",
        "                            epochs=50,\n",
        "                            validation_data = val_set_1,\n",
        "                            callbacks=callbacks_2_1,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmC0Wsc8caLa"
      },
      "outputs": [],
      "source": [
        "show_history(history_2_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt79MSfhcdFq",
        "outputId": "72e5b532-534c-41e7-c28f-67f33f909f0a"
      },
      "outputs": [],
      "source": [
        "model_2_1.load_weights(file_path_2_1)\n",
        "eval_2_1 = model_2_1.evaluate(test_set_1, verbose=2)\n",
        "print(eval_2_1)\n",
        "\n",
        "val_2_1 = model_2_1.evaluate(val_set_1, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFQs4jA3cjJq"
      },
      "outputs": [],
      "source": [
        "show_confusion_matrix(model_2_1, test_set_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtBtcib8fNTh"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_1.take(10):  # take 10 batches of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = model_2_1.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n2LDofMDrRof"
      },
      "source": [
        "# Teste 3: model 3 dataset 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gduPodukrWkG",
        "outputId": "62677ebc-e773-406f-9fc4-5feda6f7aa8e"
      },
      "outputs": [],
      "source": [
        "model_3_1 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_3_1, callbacks_3_1 = prepareCallbacks('best_3_1')\n",
        "\n",
        "history_3_1 = model_3_1.fit(train_set_1,\n",
        "                            epochs=50,\n",
        "                            validation_data = val_set_1,\n",
        "                            callbacks=callbacks_3_1,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPx0GG8irqfD",
        "outputId": "5794d51a-208f-413b-e39e-e0be144e931d"
      },
      "outputs": [],
      "source": [
        "model_3_1.load_weights(file_path_3_1)\n",
        "eval_3_1 = model_3_1.evaluate(test_set_1, verbose=2)\n",
        "print(eval_3_1)\n",
        "\n",
        "val_3_1 = model_3_1.evaluate(val_set_1, verbose=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KyB2rGqzf1Xg"
      },
      "source": [
        "# Dataset 2: processing images (rotation translate hue saturation value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob82GlanyXJM"
      },
      "outputs": [],
      "source": [
        "train_set_2 = train_set\n",
        "train_set_2 = train_set_2.cache()\n",
        "train_set_2 = train_set_2.map(process_image, num_parallel_calls = AUTOTUNE)\n",
        "train_set_2 = train_set_2.shuffle(buffer_size=30000)\n",
        "train_set_2 = train_set_2.batch(batch_size=BATCH_SIZE)\n",
        "train_set_2 = train_set_2.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_2 = val_set\n",
        "val_set_2 = val_set_2.cache()\n",
        "val_set_2 = val_set_2.batch(batch_size = BATCH_SIZE)\n",
        "val_set_2 = val_set_2.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_2 = test_set\n",
        "test_set_2 = test_set_2.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sKaZSsoLcWUS"
      },
      "source": [
        "# Teste 4: model 1 dataset 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc4JaN88ymDk",
        "outputId": "0c19f3ea-31f3-4701-f254-114533120c6a"
      },
      "outputs": [],
      "source": [
        "model_1_2 = model_I(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_1_2, callbacks_1_2 = prepareCallbacks('best_1_2')\n",
        "\n",
        "history_1_2 = model_1_2.fit(train_set_2,\n",
        "                            epochs = 30,\n",
        "                            validation_data = val_set_2,\n",
        "                            callbacks = callbacks_1_2,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jp5Hl528ZJN",
        "outputId": "91e9ad7b-b965-425a-a264-5c0278c2136c"
      },
      "outputs": [],
      "source": [
        "model_1_2.load_weights(file_path_1_2)\n",
        "eval_1_2 = model_1_2.evaluate(test_set_2, verbose=2)\n",
        "print(eval_1_2)\n",
        "\n",
        "valV1DA = model_1_2.evaluate(val_set_2, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "id": "peuDKKbMkKAl",
        "outputId": "45ae6eb3-77be-45d9-f17d-349d834341b3"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_2.take(10):  # take 10 batches of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = model_1_2.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qim2MvFqcWUU"
      },
      "source": [
        "# Teste 5: model 2 dataset 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VbBKJqq-zgO",
        "outputId": "338e0e8e-eb36-4d89-fd44-f464e802740d"
      },
      "outputs": [],
      "source": [
        "model_2_2 = model_II(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_2_2, callbacks_2_2 = prepareCallbacks('best_2_2')\n",
        "\n",
        "history_2_2 = model_2_2.fit(train_set_2,\n",
        "                            epochs = 40,\n",
        "                            validation_data = val_set_2,\n",
        "                            callbacks = callbacks_2_2,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW022z7HAZEC",
        "outputId": "fa6cdcb7-fc40-45ad-a2bc-6f9b50983a59"
      },
      "outputs": [],
      "source": [
        "model_2_2.load_weights(file_path_2_2)\n",
        "eval_2_2 = model_2_2.evaluate(test_set_2, verbose=2)\n",
        "print(eval_2_2)\n",
        "\n",
        "val_2_2 = model_2_2.evaluate(val_set_2, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lsb9F5mikijH",
        "outputId": "fb4ff95a-f68b-4426-fcc2-57926925fbf5"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_2.take(10):  # take 10 batches of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = model_2_2.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z5ILSWqfZ0H6"
      },
      "source": [
        "# Dataset 3: pre-processing (contrast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqdMxjwTn4wB"
      },
      "outputs": [],
      "source": [
        "train_set_3 = train_set\n",
        "train_set_3 = train_set_3.cache()\n",
        "train_set_3 = train_set_3.map(change_contrast, num_parallel_calls = AUTOTUNE)\n",
        "train_set_3 = train_set_3.map(process_image, num_parallel_calls = AUTOTUNE)\n",
        "train_set_3 = train_set_3.shuffle(buffer_size=30000)\n",
        "train_set_3 = train_set_3.batch(batch_size=BATCH_SIZE)\n",
        "train_set_3 = train_set_3.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_3 = val_set\n",
        "val_set_3 = val_set_3.cache()\n",
        "val_set_3 = val_set_3.map(change_contrast, num_parallel_calls = AUTOTUNE)\n",
        "val_set_3 = val_set_3.batch(batch_size = BATCH_SIZE)\n",
        "val_set_3 = val_set_3.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_3 = test_set\n",
        "test_set_3 = test_set_3.map(change_contrast, num_parallel_calls = AUTOTUNE)\n",
        "test_set_3 = test_set_3.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9NAxlCbeH5-w"
      },
      "source": [
        "# Teste 6: model 1 dataset 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3Mc5_ujrMOI",
        "outputId": "dd9ca4a4-b81c-4168-b64c-5453ed323c3a"
      },
      "outputs": [],
      "source": [
        "model_1_3 = model_I(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_1_3, callbacks_1_3 = prepareCallbacks('best_1_3')\n",
        "\n",
        "history_1_3 = model_1_3.fit(train_set_3,\n",
        "                            epochs = 35,\n",
        "                            validation_data = val_set_3,\n",
        "                            callbacks = callbacks_1_3,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJVl9-MErlG6",
        "outputId": "1e04b3f4-7836-4082-e2bb-793c225b42c6"
      },
      "outputs": [],
      "source": [
        "model_1_3.load_weights(file_path_1_3)\n",
        "eval_1_3 = model_1_3.evaluate(test_set_3, verbose=2)\n",
        "print(eval_1_3)\n",
        "\n",
        "valV1PP = model_1_3.evaluate(val_set_3, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NoJ8O3EwN-xF",
        "outputId": "95266159-6e97-4249-dff2-21db05867294"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_3.take(10):  # take 10 batches of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = model_1_3.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OC17zmzQH5-x"
      },
      "source": [
        "# Teste 7: model 2 dataset 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NfoDnd4gtxjZ",
        "outputId": "1f2317e7-90b5-4d23-99c6-f82f347319cc"
      },
      "outputs": [],
      "source": [
        "model_2_3 = model_II(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_2_3, callbacks_2_3 = prepareCallbacks('best_2_3')\n",
        "\n",
        "history_2_3 = model_2_3.fit(train_set_3,\n",
        "                            epochs = 50,\n",
        "                            validation_data = val_set_3,\n",
        "                            callbacks = callbacks_2_3,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz5g4pnYH5-y",
        "outputId": "054c50f4-74e9-4a01-9cba-4a10a1cafa94"
      },
      "outputs": [],
      "source": [
        "model_2_3.load_weights(file_path_2_3)\n",
        "eval_2_3 = model_2_3.evaluate(test_set_3, verbose=2)\n",
        "print(eval_2_3)\n",
        "\n",
        "val_2_3 = model_2_3.evaluate(val_set_3,verbose=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MkZ_clL1kkfG"
      },
      "source": [
        "# Dataset 4: dynamic - color transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3iSldflhsRI"
      },
      "outputs": [],
      "source": [
        "train_set_4 = train_set\n",
        "train_set_4 = train_set_4.cache()\n",
        "train_set_4 = train_set_4.map(process_hue, num_parallel_calls = AUTOTUNE)\n",
        "train_set_4 = train_set_4.map(process_saturation, num_parallel_calls = AUTOTUNE)\n",
        "train_set_4 = train_set_4.map(process_brightness, num_parallel_calls = AUTOTUNE)\n",
        "train_set_4 = train_set_4.shuffle(buffer_size=30000)\n",
        "train_set_4 = train_set_4.batch(batch_size=BATCH_SIZE)\n",
        "train_set_4 = train_set_4.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_4 = val_set\n",
        "val_set_4 = val_set_4.cache()\n",
        "val_set_4 = val_set_4.batch(batch_size = BATCH_SIZE)\n",
        "val_set_4 = val_set_4.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_4 = test_set\n",
        "test_set_4 = test_set_4.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lW_oiA_olPtB"
      },
      "source": [
        "# Teste 8: model 1 dataset 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUfinJXjhsRI",
        "outputId": "049af240-5550-482b-a84d-9fc168d857b9"
      },
      "outputs": [],
      "source": [
        "model_1_4 = model_I(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_1_4, callbacks_1_4 = prepareCallbacks('best_1_4')\n",
        "\n",
        "history_1_4 = model_1_4.fit(train_set_4,\n",
        "                            epochs = 50,\n",
        "                            validation_data = val_set_4,\n",
        "                            callbacks = callbacks_1_4,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_wk0UrkhsRI",
        "outputId": "29581808-2441-4f70-ed78-b98881213ee5"
      },
      "outputs": [],
      "source": [
        "model_1_4.load_weights(file_path_1_4)\n",
        "eval_1_4 = model_1_4.evaluate(test_set_4, verbose=2)\n",
        "print(eval_1_4)\n",
        "\n",
        "val_1_4 = model_1_4.evaluate(val_set_4, verbose=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SADKJXcLlmjx"
      },
      "source": [
        "# Teste 9: model 2 dataset 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_azBN9MhsRJ",
        "outputId": "befb14c6-dd69-4667-dd0f-76c992772c5f"
      },
      "outputs": [],
      "source": [
        "model_2_4 = model_II(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_2_4, callbacks_2_4 = prepareCallbacks('best_2_4')\n",
        "\n",
        "history_2_4 = model_2_4.fit(train_set_4,\n",
        "                            epochs = 50,\n",
        "                            validation_data = val_set_4,\n",
        "                            callbacks = callbacks_2_4,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqKu-LvLhsRJ",
        "outputId": "73a8b73f-2fd3-4482-e8e1-fb672717f8bb"
      },
      "outputs": [],
      "source": [
        "model_2_4.load_weights(file_path_2_4)\n",
        "eval_2_4 = model_2_4.evaluate(test_set_4, verbose=2)\n",
        "print(eval_2_4)\n",
        "\n",
        "val_2_4 = model_2_4.evaluate(val_set_4, verbose=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ugKmv3gUlZXb"
      },
      "source": [
        "# Teste 10: model 3 dataset 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcwiQ9Q4lbyV",
        "outputId": "27f6f2b8-4deb-4871-eec4-5ad519327633"
      },
      "outputs": [],
      "source": [
        "model_3_4 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_3_4, callbacks_3_4 = prepareCallbacks('best_3_4')\n",
        "\n",
        "history_3_4 = model_3_4.fit(train_set_4,\n",
        "                            epochs = 50,\n",
        "                            validation_data = val_set_4,\n",
        "                            callbacks = callbacks_3_4,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzwBCeeKlxhe",
        "outputId": "e697473a-c6e2-43a5-cf84-64501056c882"
      },
      "outputs": [],
      "source": [
        "model_3_4.load_weights(file_path_3_4)\n",
        "eval_3_4 = model_3_4.evaluate(test_set_4, verbose=2)\n",
        "print(eval_3_4)\n",
        "\n",
        "val_3_4 = model_3_4.evaluate(val_set_4, verbose=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D89YamoFH5-z"
      },
      "source": [
        "# Dataset 5: data augmentation - geometric transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc-FOSZLQio2"
      },
      "outputs": [],
      "source": [
        "train_set_5 = train_set\n",
        "train_set_5 = train_set_5.concatenate(train_set.map(process_hue, num_parallel_calls = AUTOTUNE))\n",
        "train_set_5 = train_set_5.concatenate(train_set.map(process_saturation, num_parallel_calls = AUTOTUNE))\n",
        "train_set_5 = train_set_5.concatenate(train_set.map(process_brightness, num_parallel_calls = AUTOTUNE))\n",
        "train_set_5 = train_set_5.concatenate(train_set.map(process_perspective, num_parallel_calls = AUTOTUNE))\n",
        "train_set_5 = train_set_5.concatenate(train_set.map(process_translate, num_parallel_calls = AUTOTUNE))\n",
        "train_set_5 = train_set_5.concatenate(train_set.map(process_rotation, num_parallel_calls = AUTOTUNE))\n",
        "train_set_5 = train_set_5.concatenate(train_set.map(process_shear, num_parallel_calls = AUTOTUNE))\n",
        "train_set_5 = train_set_5.concatenate(train_set.map(process_crop, num_parallel_calls = AUTOTUNE))\n",
        "train_set_5 = train_set_5.cache()\n",
        "train_set_5 = train_set_5.shuffle(buffer_size=30000)\n",
        "train_set_5 = train_set_5.batch(batch_size=BATCH_SIZE)\n",
        "train_set_5 = train_set_5.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_5 = val_set\n",
        "val_set_5 = val_set_5.cache()\n",
        "val_set_5 = val_set_5.batch(batch_size = BATCH_SIZE)\n",
        "val_set_5 = val_set_5.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_5 = test_set\n",
        "test_set_5 = test_set_5.batch(batch_size = BATCH_SIZE)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yKvS6S2zH5-0"
      },
      "source": [
        "# Teste 11: model 1 dataset 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BpY7NpuRsre",
        "outputId": "62cc96a5-c7ad-4c39-fc6b-47688b301bad"
      },
      "outputs": [],
      "source": [
        "model_1_5 = model_I(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_1_5, callbacks_1_5 = prepareCallbacks('best_1_5')\n",
        "\n",
        "history_1_5 = model_1_5.fit(train_set_5,\n",
        "                            epochs = 50,\n",
        "                            validation_data = val_set_5,\n",
        "                            callbacks = callbacks_1_5,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjOU_8EKd_VA",
        "outputId": "98f2678b-6395-4c58-b2e4-dbfb3f65a870"
      },
      "outputs": [],
      "source": [
        "model_1_5.load_weights(file_path_1_5)\n",
        "eval_1_5 = model_1_5.evaluate(test_set_5, verbose=2)\n",
        "print(eval_1_5)\n",
        "\n",
        "val_1_5 = model_1_5.evaluate(val_set_5, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "Vov2f_g20pW1",
        "outputId": "d8c74129-f1c5-49a8-9b20-90f885ac3dff"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_5.take(10):  # take 10 batches of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = model_1_5.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A9tjiKUrY-gz"
      },
      "source": [
        "# Teste 12: model 2 dataset 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYSHOVCiZGfD",
        "outputId": "bcbd5f34-e8f7-4903-e0f7-7986d77d11ec"
      },
      "outputs": [],
      "source": [
        "model_2_5 = model_II(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_2_5, callbacks_2_5 = prepareCallbacks('best_2_5')\n",
        "\n",
        "history_2_5 = model_2_5.fit(train_set_5,\n",
        "                            epochs = 50,\n",
        "                            validation_data = val_set_5,\n",
        "                            callbacks = callbacks_2_5,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVSTQ0p3aVHg",
        "outputId": "223cbe09-149c-48c4-b1a6-9494f2b18461"
      },
      "outputs": [],
      "source": [
        "model_2_5.load_weights(file_path_2_5)\n",
        "eval_2_5 = model_2_5.evaluate(test_set_5, verbose=2)\n",
        "print(eval_2_5)\n",
        "\n",
        "val_2_5 = model_2_5.evaluate(val_set_5, verbose=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rOqM-3SzAzPa"
      },
      "source": [
        "# Teste 13: model 3 dataset 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nYzljH0A3NZ",
        "outputId": "27265d33-b94c-4d0b-c58d-b33434902ab7"
      },
      "outputs": [],
      "source": [
        "model_3_5 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_3_5, callbacks_3_5 = prepareCallbacks('best_3_5')\n",
        "\n",
        "history_3_5 = model_3_5.fit(train_set_5,\n",
        "                            epochs = 50,\n",
        "                            validation_data = val_set_5,\n",
        "                            callbacks = callbacks_3_5,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjFmC_-FA_VH",
        "outputId": "cbd06160-857a-488a-d57c-b68adf2247f0"
      },
      "outputs": [],
      "source": [
        "model_3_5.load_weights(file_path_3_5)\n",
        "eval_3_5 = model_3_5.evaluate(test_set_5, verbose=2)\n",
        "print(eval_3_5)\n",
        "\n",
        "val_3_5 = model_3_5.evaluate(val_set_5, verbose=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TH_A5HVpmyaX"
      },
      "source": [
        "# Dataset 6: data augmentation - disturbance transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXaqZZWOnKmn"
      },
      "outputs": [],
      "source": [
        "train_set_6 = train_set\n",
        "train_set_6 = train_set_6.concatenate(train_set.map(process_hue, num_parallel_calls = AUTOTUNE))\n",
        "train_set_6 = train_set_6.concatenate(train_set.map(process_saturation, num_parallel_calls = AUTOTUNE))\n",
        "train_set_6 = train_set_6.concatenate(train_set.map(process_brightness, num_parallel_calls = AUTOTUNE))\n",
        "train_set_6 = train_set_6.concatenate(train_set.map(process_perspective, num_parallel_calls = AUTOTUNE))\n",
        "train_set_6 = train_set_6.concatenate(train_set.map(process_translate, num_parallel_calls = AUTOTUNE))\n",
        "train_set_6 = train_set_6.concatenate(train_set.map(process_rotation, num_parallel_calls = AUTOTUNE))\n",
        "train_set_6 = train_set_6.concatenate(train_set.map(process_shear, num_parallel_calls = AUTOTUNE))\n",
        "train_set_6 = train_set_6.concatenate(train_set.map(process_crop, num_parallel_calls = AUTOTUNE))\n",
        "train_set_6 = train_set_6.concatenate(train_set.map(apply_perlin, num_parallel_calls = AUTOTUNE))\n",
        "train_set_6 = train_set_6.concatenate(train_set.map(apply_blur, num_parallel_calls = AUTOTUNE))\n",
        "train_set_6 = train_set_6.cache()\n",
        "train_set_6 = train_set_6.shuffle(buffer_size=30000)\n",
        "train_set_6 = train_set_6.batch(batch_size=BATCH_SIZE)\n",
        "train_set_6 = train_set_6.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_6 = val_set\n",
        "val_set_6 = val_set_6.cache()\n",
        "val_set_6 = val_set_6.batch(batch_size = BATCH_SIZE)\n",
        "val_set_6 = val_set_6.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_6 = test_set\n",
        "test_set_6 = test_set_6.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TTbFkH5yn1Bc"
      },
      "source": [
        "# Teste 14: model 3 dataset 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vX80O1qkn7n0",
        "outputId": "c2f11a12-f4da-4a80-be2b-5d6c750f7de0"
      },
      "outputs": [],
      "source": [
        "model_3_6 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_3_6, callbacks_3_6 = prepareCallbacks('best_3_6')\n",
        "\n",
        "history_3_6 = model_3_6.fit(train_set_6,\n",
        "                            epochs = 50,\n",
        "                            validation_data = val_set_6,\n",
        "                            callbacks = callbacks_3_6,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do6ySViMoSJl"
      },
      "outputs": [],
      "source": [
        "model_3_6.load_weights(file_path_3_6)\n",
        "eval_3_6 = model_3_6.evaluate(test_set_6, verbose=2)\n",
        "print(eval_3_6)\n",
        "\n",
        "val_3_6 = model_3_6.evaluate(val_set_6, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nt4sr2aTBedB",
        "outputId": "64c885a7-46cd-4d51-fa17-56788636447b"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_6.take(-1):  # take 10 batches of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = model_3_6.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa-5MXsncWUd"
      },
      "source": [
        "# Dataset 7: data augmentation - oclusion transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP8SQD8E3a5W"
      },
      "outputs": [],
      "source": [
        "train_set_7 = train_set\n",
        "train_set_7 = train_set_7.concatenate(train_set.map(process_perspective, num_parallel_calls = AUTOTUNE))\n",
        "train_set_7 = train_set_7.concatenate(train_set.map(process_crop, num_parallel_calls = AUTOTUNE))\n",
        "train_set_7 = train_set_7.concatenate(train_set.map(apply_perlin, num_parallel_calls = AUTOTUNE))\n",
        "train_set_7 = train_set_7.concatenate(train_set.map(apply_blur, num_parallel_calls = AUTOTUNE))\n",
        "train_set_7 = train_set_7.concatenate(train_set.map(process_erasing, num_parallel_calls = AUTOTUNE))\n",
        "train_set_7 = train_set_7.cache()\n",
        "train_set_7 = train_set_7.map(process_image_testing, num_parallel_calls = AUTOTUNE)\n",
        "train_set_7 = train_set_7.shuffle(buffer_size=30000)\n",
        "train_set_7 = train_set_7.batch(batch_size=BATCH_SIZE)\n",
        "train_set_7 = train_set_7.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_7 = val_set\n",
        "val_set_7 = val_set_7.cache()\n",
        "val_set_7 = val_set_7.batch(batch_size = BATCH_SIZE)\n",
        "val_set_7 = val_set_7.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_7 = test_set\n",
        "test_set_7 = test_set_7.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SpJgxBOVokTf"
      },
      "source": [
        "# Teste 15: model 3 dataset 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1fMEHPm433YJ",
        "outputId": "48011017-453b-422c-e72d-1972ed4d36d5"
      },
      "outputs": [],
      "source": [
        "model_3_7 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_3_7, callbacks_3_7 = prepareCallbacks('best_3_7')\n",
        "\n",
        "history_3_7 = model_3_7.fit(train_set_7,\n",
        "                            epochs = 50,\n",
        "                            validation_data = val_set_7,\n",
        "                            callbacks = callbacks_3_7,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzIT08Dz4HWi",
        "outputId": "a5326463-bf3a-4298-abfe-6e397e17071d"
      },
      "outputs": [],
      "source": [
        "model_3_7.load_weights(file_path_3_7)\n",
        "eval_3_7 = model_3_7.evaluate(test_set_7, verbose=2)\n",
        "print(eval_3_7)\n",
        "\n",
        "val_3_7 = model_3_7.evaluate(val_set_7,verbose=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WjfMMi5hJf-r"
      },
      "source": [
        "# Dataset 8: data augmentation - add gaussian blur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPUrOeWwJkIk"
      },
      "outputs": [],
      "source": [
        "train_set_8 = train_set\n",
        "train_set_8 = train_set_8.concatenate(train_set.map(process_brightness, num_parallel_calls = AUTOTUNE))\n",
        "train_set_8 = train_set_8.concatenate(train_set.map(process_contrast, num_parallel_calls = AUTOTUNE))\n",
        "train_set_8 = train_set_8.concatenate(train_set.map(process_rotation, num_parallel_calls = AUTOTUNE))\n",
        "train_set_8 = train_set_8.concatenate(train_set.map(process_zoom, num_parallel_calls = AUTOTUNE))\n",
        "train_set_8 = train_set_8.concatenate(train_set.map(augment_blur, num_parallel_calls = AUTOTUNE))\n",
        "\n",
        "lenght = train_set_8.cardinality().numpy()\n",
        "\n",
        "train_set_8 = train_set_8.cache()\n",
        "train_set_8 = train_set_8.shuffle(buffer_size=lenght)\n",
        "train_set_8 = train_set_8.batch(batch_size=BATCH_SIZE)\n",
        "train_set_8 = train_set_8.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_8 = val_set\n",
        "val_set_8 = val_set_8.cache()\n",
        "val_set_8 = val_set_8.batch(batch_size = BATCH_SIZE)\n",
        "val_set_8 = val_set_8.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_8 = test_set\n",
        "test_set_8 = test_set_8.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji89wulccWUl"
      },
      "source": [
        "# Teste 16: model 1 dataset 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zCYBQ2-aJfgc",
        "outputId": "cdd0cf29-3864-4920-fec6-96ad017f997e"
      },
      "outputs": [],
      "source": [
        "model_1_8 = model_I(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_1_8, callbacks_1_8 = prepareCallbacks('best_1_8')\n",
        "\n",
        "history_1_8 = model_1_8.fit(train_set_8,\n",
        "                            epochs = 50,\n",
        "                            validation_data = val_set_8,\n",
        "                            callbacks = callbacks_1_8,\n",
        "                            verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naI_ZoT8T6v6",
        "outputId": "301a7ee9-cf11-488b-8354-d7d8f49faf43"
      },
      "outputs": [],
      "source": [
        "model_1_8.load_weights(file_path_1_8)\n",
        "eval_1_8 = model_1_8.evaluate(test_set_8, verbose=2)\n",
        "print(eval_1_8)\n",
        "\n",
        "val_1_8 = model_1_8.evaluate(val_set_8,verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JXJAiGAoUn--",
        "outputId": "d1881e46-3217-434a-e6b4-f6efda4c67be"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_8.take(10):  # take 10 batches of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = model_1_8.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UWBzYDY_JrGn"
      },
      "source": [
        "# Dataset 9: data augmentation - add contornos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXs8qJmbJs5n"
      },
      "outputs": [],
      "source": [
        "train_set_9 = train_set\n",
        "# train_set_9 = train_set_9.concatenate(train_set.map(process_brightness, num_parallel_calls = AUTOTUNE))\n",
        "# train_set_9 = train_set_9.concatenate(train_set.map(process_contrast, num_parallel_calls = AUTOTUNE))\n",
        "# train_set_9 = train_set_9.concatenate(train_set.map(process_rotation, num_parallel_calls = AUTOTUNE))\n",
        "# train_set_9 = train_set_9.concatenate(train_set.map(process_zoom, num_parallel_calls = AUTOTUNE))\n",
        "train_set_9 = train_set_9.concatenate(train_set.map(gaussian_laplace, num_parallel_calls = AUTOTUNE))\n",
        "train_set_9 = train_set_9.cache()\n",
        "train_set_9 = train_set_9.shuffle(buffer_size=30000)\n",
        "train_set_9 = train_set_9.batch(batch_size=BATCH_SIZE)\n",
        "train_set_9 = train_set_9.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_9 = val_set\n",
        "val_set_9 = val_set_9.batch(batch_size = BATCH_SIZE)\n",
        "val_set_9 = val_set_9.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_9 = test_set\n",
        "test_set_9 = test_set_9.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xyJH5_6ZcWUp"
      },
      "source": [
        "# Teste 17: model 1 dataset 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CXclroPJuWc",
        "outputId": "63b8cdf5-2940-4785-c863-fa1b44a89ec1"
      },
      "outputs": [],
      "source": [
        "model_1_9 = model_I(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_1_9, callbacks_1_9 = prepareCallbacks('best_1_9')\n",
        "\n",
        "history_1_9 = model_1_9.fit(train_set_9,\n",
        "                            epochs = 30,\n",
        "                            validation_data = val_set_9,\n",
        "                            callbacks = callbacks_1_9,\n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJZQf9MYJwYL"
      },
      "outputs": [],
      "source": [
        "model_1_9.load_weights(file_path_1_9)\n",
        "eval_1_9 = model_1_9.evaluate(test_set_9, verbose=2)\n",
        "print(eval_1_9)\n",
        "\n",
        "val_1_9 = model_1_9.evaluate(val_set_9, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "OhY-fGenJx4s",
        "outputId": "f1778f7c-78d4-4af6-ef46-db395fa897b6"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_9.take(10):  # take 10 batches of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = model_1_9.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "42bG0giPhsRV"
      },
      "source": [
        "# Dataset 10: concat best transformations and dynamic augmentation\n",
        "-using only model3 since it was the one who get the best results until now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC3BxU0chsRV"
      },
      "outputs": [],
      "source": [
        "train_set_10 = train_set\n",
        "train_set_10 = train_set_10.concatenate(train_set.map(apply_perlin, num_parallel_calls = AUTOTUNE))\n",
        "train_set_10 = train_set_10.concatenate(train_set.map(apply_blur, num_parallel_calls = AUTOTUNE))\n",
        "train_set_10 = train_set_10.concatenate(train_set.map(process_perspective,num_parallel_calls=AUTOTUNE))\n",
        "train_set_10 = train_set_10.concatenate(train_set.map(process_crop,num_parallel_calls=AUTOTUNE))\n",
        "train_set_10 = train_set_10.concatenate(train_set.map(process_erasing,num_parallel_calls=AUTOTUNE))\n",
        "train_set_10 = train_set_10.concatenate(train_set.map(process_translate, num_parallel_calls = AUTOTUNE))\n",
        "train_set_10 = train_set_10.concatenate(train_set.map(process_rotation, num_parallel_calls = AUTOTUNE))\n",
        "train_set_10 = train_set_10.cache()\n",
        "train_set_10 = train_set_10.map(process_image_testing, num_parallel_calls = AUTOTUNE)\n",
        "train_set_10 = train_set_10.shuffle(buffer_size=30000)\n",
        "train_set_10 = train_set_10.batch(batch_size=BATCH_SIZE)\n",
        "train_set_10 = train_set_10.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_10 = val_set\n",
        "val_set_10 = val_set_10.cache()\n",
        "val_set_10 = val_set_10.batch(batch_size = BATCH_SIZE)\n",
        "val_set_10 = val_set_10.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_10 = test_set\n",
        "test_set_10 = test_set_10.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Teste 18: model 3 dataset 10 -> Accuracy: 99.44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ixpb6rSShsRV",
        "outputId": "46a9dfda-8bd7-448a-b4fe-2316a63eea98"
      },
      "outputs": [],
      "source": [
        "model_3_10 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "file_path_3_10, callbacks_3_10 = prepareCallbacks('best_3_12')\n",
        "history_3_10 = model_3_10.fit(train_set_10,\n",
        "                              epochs = 50,\n",
        "                              validation_data = val_set_10,\n",
        "                              callbacks = callbacks_3_10,\n",
        "                              verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJkri3u0hsRW"
      },
      "outputs": [],
      "source": [
        "model_3_10.load_weights(file_path_3_10)\n",
        "eval_3_10 = model_3_10.evaluate(test_set_10, verbose=2)\n",
        "print(eval_3_10)\n",
        "\n",
        "val_3_10 = model_3_10.evaluate(val_set_10, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em7Wi0BzhsRW"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_10.take(-1):  # take 10 batches of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = model_3_10.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xNNyEcm5RCOs"
      },
      "source": [
        "# Dataset 11: add conffeti noise and prob. erasing = 1 and stronger perlin noise\n",
        "-using only model3 since it was the one who get the best results until now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmzNJcR8RCOt"
      },
      "outputs": [],
      "source": [
        "train_set_11 = train_set\n",
        "train_set_11 = train_set_11.concatenate(train_set.map(process_confetti_noise, num_parallel_calls = AUTOTUNE))\n",
        "train_set_11 = train_set_11.concatenate(train_set.map(apply_perlin, num_parallel_calls = AUTOTUNE))\n",
        "train_set_11 = train_set_11.concatenate(train_set.map(apply_blur, num_parallel_calls = AUTOTUNE))\n",
        "train_set_11 = train_set_11.concatenate(train_set.map(process_perspective,num_parallel_calls=AUTOTUNE))\n",
        "train_set_11 = train_set_11.concatenate(train_set.map(process_crop,num_parallel_calls=AUTOTUNE))\n",
        "train_set_11 = train_set_11.concatenate(train_set.map(process_erasing,num_parallel_calls=AUTOTUNE))\n",
        "train_set_11 = train_set_11.concatenate(train_set.map(process_translate, num_parallel_calls = AUTOTUNE))\n",
        "train_set_11 = train_set_11.concatenate(train_set.map(process_rotation, num_parallel_calls = AUTOTUNE))\n",
        "train_set_11 = train_set_11.cache()\n",
        "train_set_11 = train_set_11.map(process_image_testing, num_parallel_calls = AUTOTUNE)\n",
        "train_set_11 = train_set_11.shuffle(buffer_size=30000)\n",
        "train_set_11 = train_set_11.batch(batch_size=BATCH_SIZE)\n",
        "train_set_11 = train_set_11.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_11 = val_set\n",
        "val_set_11 = val_set_11.cache()\n",
        "val_set_11 = val_set_11.batch(batch_size = BATCH_SIZE)\n",
        "val_set_11 = val_set_11.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_11 = test_set\n",
        "test_set_11 = test_set_11.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Teste 19: model 3 dataset 11 -> Accuracy: 99.22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wQ-_rNgR3Tg",
        "outputId": "6e0ae2ea-5e0b-49ce-f545-7d2bb2e90a1f"
      },
      "outputs": [],
      "source": [
        "model_3_11 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "model_3_11.load_weights('./cp.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIqYwkYtRCOt"
      },
      "outputs": [],
      "source": [
        "file_path_3_11, callbacks_3_11 = prepareCallbacks('best_3_11')\n",
        "history_3_11 = model_3_11.fit(train_set_11,\n",
        "                              epochs = 50,\n",
        "                              validation_data = val_set_11,\n",
        "                              callbacks = callbacks_3_11,\n",
        "                              verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUxFq1BcR-kZ",
        "outputId": "61ecc490-4ff3-49cf-c182-a10e10d92134"
      },
      "outputs": [],
      "source": [
        "eval_3_11 = model_3_11.evaluate(test_set_11, verbose=2)\n",
        "print(eval_3_11)\n",
        "\n",
        "val_3_11 = model_3_11.evaluate(val_set_11, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X3yHi5x5RCOt",
        "outputId": "c7960e6c-b7b5-40e5-a548-7f053e13d79a"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_11.take(-1):  # take 10 batches of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = model_3_11.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ocNLuofrTQSq"
      },
      "source": [
        "# Dataset 12: concat all pre-processing\n",
        "-using only model3 since it was the one who get the best results until now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuvTT2jITPwq"
      },
      "outputs": [],
      "source": [
        "train_set_12 = train_set\n",
        "train_set_12 = train_set_12.concatenate(train_set.map(apply_perlin, num_parallel_calls = AUTOTUNE))\n",
        "train_set_12 = train_set_12.concatenate(train_set.map(apply_blur, num_parallel_calls = AUTOTUNE))\n",
        "train_set_12 = train_set_12.concatenate(train_set.map(process_perspective,num_parallel_calls=AUTOTUNE))\n",
        "train_set_12 = train_set_12.concatenate(train_set.map(process_crop,num_parallel_calls=AUTOTUNE))\n",
        "train_set_12 = train_set_12.concatenate(train_set.map(process_erasing,num_parallel_calls=AUTOTUNE))\n",
        "train_set_12 = train_set_12.concatenate(train_set.map(process_translate, num_parallel_calls = AUTOTUNE))\n",
        "train_set_12 = train_set_12.concatenate(train_set.map(process_rotation, num_parallel_calls = AUTOTUNE))\n",
        "train_set_12 = train_set_12.concatenate(train_set.map(process_shear,num_parallel_calls=AUTOTUNE))\n",
        "train_set_12 = train_set_12.concatenate(train_set.map(process_hue,num_parallel_calls=AUTOTUNE))\n",
        "train_set_12 = train_set_12.concatenate(train_set.map(process_saturation, num_parallel_calls = AUTOTUNE))\n",
        "train_set_12 = train_set_12.concatenate(train_set.map(process_brightness, num_parallel_calls = AUTOTUNE))\n",
        "train_set_12 = train_set_12.cache()\n",
        "train_set_12 = train_set_12.shuffle(buffer_size=50000)\n",
        "train_set_12 = train_set_12.batch(batch_size=BATCH_SIZE)\n",
        "train_set_12 = train_set_12.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_12 = val_set\n",
        "val_set_12 = val_set_12.cache()\n",
        "val_set_12 = val_set_12.batch(batch_size = BATCH_SIZE)\n",
        "val_set_12 = val_set_12.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_12 = test_set\n",
        "test_set_12 = test_set_12.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Teste 20: model 3 dataset 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_3_12 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "model_3_12.load_weights('./cp.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tHsz6mlUKcL",
        "outputId": "26203ee8-2668-4784-ef93-e97ffd5b849d"
      },
      "outputs": [],
      "source": [
        "file_path_3_12, callbacks_3_12 = prepareCallbacks('best_3_12')\n",
        "history_3_12 = model_3_12.fit(train_set_12,\n",
        "                              epochs = 50,\n",
        "                              validation_data = val_set_12,\n",
        "                              callbacks = callbacks_3_12,\n",
        "                              verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr0ObHuAUKSa",
        "outputId": "5ce05e77-0f2b-45cc-83e3-921d2926b8c8"
      },
      "outputs": [],
      "source": [
        "eval_3_12 = model_3_12.evaluate(test_set_12, verbose=2)\n",
        "print(eval_3_12)\n",
        "\n",
        "val_3_12 = model_3_12.evaluate(val_set_12, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DIniwhK4UKDI",
        "outputId": "35ce2dda-6aeb-494f-cf47-f402a55b7585"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_12.take(-1):  # take 10 batches of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = model_3_12.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset 13: add random vertical and horizontal lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set_13 = train_set\n",
        "train_set_13 = train_set_13.concatenate(train_set.map(apply_perlin, num_parallel_calls = AUTOTUNE))\n",
        "train_set_13 = train_set_13.concatenate(train_set.map(apply_blur, num_parallel_calls = AUTOTUNE))\n",
        "train_set_13 = train_set_13.concatenate(train_set.map(process_perspective,num_parallel_calls=AUTOTUNE))\n",
        "train_set_13 = train_set_13.concatenate(train_set.map(process_erasing,num_parallel_calls=AUTOTUNE))\n",
        "train_set_13 = train_set_13.concatenate(train_set.map(process_translate, num_parallel_calls = AUTOTUNE))\n",
        "train_set_13 = train_set_13.concatenate(train_set.map(process_rotation, num_parallel_calls = AUTOTUNE))\n",
        "train_set_13 = train_set_13.concatenate(train_set.map(process_crop, num_parallel_calls = AUTOTUNE))\n",
        "train_set_13 = train_set_13.concatenate(train_set.map(process_vlines, num_parallel_calls = AUTOTUNE))\n",
        "train_set_13 = train_set_13.concatenate(train_set.map(process_hlines, num_parallel_calls = AUTOTUNE))\n",
        "train_set_13 = train_set_13.cache()\n",
        "train_set_13 = train_set_13.map(process_shear, num_parallel_calls = AUTOTUNE)\n",
        "train_set_13 = train_set_13.map(process_hue, num_parallel_calls = AUTOTUNE)\n",
        "train_set_13 = train_set_13.map(process_saturation, num_parallel_calls = AUTOTUNE)\n",
        "train_set_13 = train_set_13.map(process_brightness, num_parallel_calls = AUTOTUNE)\n",
        "train_set_13 = train_set_13.shuffle(buffer_size=50000)\n",
        "train_set_13 = train_set_13.batch(batch_size=BATCH_SIZE)\n",
        "train_set_13 = train_set_13.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_13 = val_set\n",
        "val_set_13 = val_set_13.cache()\n",
        "val_set_13 = val_set_13.batch(batch_size = BATCH_SIZE)\n",
        "val_set_13 = val_set_13.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_13 = test_set\n",
        "test_set_13 = test_set_13.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Teste 21: model 3 dataset 13 -> Accuracy: 99.38"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_3_13 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "model_3_13.load_weights('./cp.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path_3_13, callbacks_3_13 = prepareCallbacks('best_3_13')\n",
        "history_3_13 = model_3_13.fit(train_set_13,\n",
        "                              epochs = 50,\n",
        "                              validation_data = val_set_13,\n",
        "                              callbacks = callbacks_3_13,\n",
        "                              verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_3_13 = model_3_13.evaluate(test_set_13, verbose=2)\n",
        "print(eval_3_13)\n",
        "\n",
        "val_3_13 = model_3_13.evaluate(val_set_13, verbose=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset 14: different combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set_14 = train_set\n",
        "train_set_14 = train_set_14.concatenate(train_set.map(apply_perlin, num_parallel_calls = AUTOTUNE))\n",
        "train_set_14 = train_set_14.concatenate(train_set.map(apply_blur, num_parallel_calls = AUTOTUNE))\n",
        "train_set_14 = train_set_14.concatenate(train_set.map(process_perspective,num_parallel_calls=AUTOTUNE))\n",
        "train_set_14 = train_set_14.concatenate(train_set.map(process_erasing,num_parallel_calls=AUTOTUNE))\n",
        "train_set_14 = train_set_14.concatenate(train_set.map(process_translate, num_parallel_calls = AUTOTUNE))\n",
        "train_set_14 = train_set_14.concatenate(train_set.map(process_rotation, num_parallel_calls = AUTOTUNE))\n",
        "train_set_14 = train_set_14.concatenate(train_set.map(process_shear, num_parallel_calls = AUTOTUNE))\n",
        "train_set_14 = train_set_14.cache()\n",
        "train_set_14 = train_set_14.map(process_hue, num_parallel_calls = AUTOTUNE)\n",
        "train_set_14 = train_set_14.map(process_saturation, num_parallel_calls = AUTOTUNE)\n",
        "train_set_14 = train_set_14.map(process_brightness, num_parallel_calls = AUTOTUNE)\n",
        "train_set_14 = train_set_14.shuffle(buffer_size=30000)\n",
        "train_set_14 = train_set_14.batch(batch_size=BATCH_SIZE)\n",
        "train_set_14 = train_set_14.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_14 = val_set\n",
        "val_set_14 = val_set_14.cache()\n",
        "val_set_14 = val_set_14.batch(batch_size = BATCH_SIZE)\n",
        "val_set_14 = val_set_14.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_14 = test_set\n",
        "test_set_14 = test_set_14.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Teste 22: model 3 dataset 14 -> Accuracy: 99.26"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_3_14 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "model_3_14.load_weights('./cp.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path_3_14, callbacks_3_14 = prepareCallbacks('best_3_14')\n",
        "history_3_14 = model_3_14.fit(train_set_14,\n",
        "                              epochs = 50,\n",
        "                              validation_data = val_set_14,\n",
        "                              callbacks = callbacks_3_14,\n",
        "                              verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_3_14 = model_3_14.evaluate(test_set_14, verbose=2)\n",
        "print(eval_3_14)\n",
        "\n",
        "val_3_14 = model_3_14.evaluate(val_set_14, verbose=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset 15: different combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set_15 = train_set\n",
        "train_set_15 = train_set_15.concatenate(train_set.map(apply_perlin, num_parallel_calls = AUTOTUNE))\n",
        "train_set_15 = train_set_15.concatenate(train_set.map(apply_blur, num_parallel_calls = AUTOTUNE))\n",
        "train_set_15 = train_set_15.concatenate(train_set.map(process_perspective,num_parallel_calls=AUTOTUNE))\n",
        "train_set_15 = train_set_15.concatenate(train_set.map(process_erasing,num_parallel_calls=AUTOTUNE))\n",
        "train_set_15 = train_set_15.concatenate(train_set.map(process_translate, num_parallel_calls = AUTOTUNE))\n",
        "train_set_15 = train_set_15.concatenate(train_set.map(process_rotation, num_parallel_calls = AUTOTUNE))\n",
        "train_set_15 = train_set_15.cache()\n",
        "train_set_15 = train_set_15.map(process_shear, num_parallel_calls = AUTOTUNE)\n",
        "train_set_15 = train_set_15.map(process_hue, num_parallel_calls = AUTOTUNE)\n",
        "train_set_15 = train_set_15.map(process_saturation, num_parallel_calls = AUTOTUNE)\n",
        "train_set_15 = train_set_15.map(process_brightness, num_parallel_calls = AUTOTUNE)\n",
        "train_set_15 = train_set_15.shuffle(buffer_size=30000)\n",
        "train_set_15 = train_set_15.batch(batch_size=BATCH_SIZE)\n",
        "train_set_15 = train_set_15.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "val_set_15 = val_set\n",
        "val_set_15 = val_set_15.cache()\n",
        "val_set_15 = val_set_15.batch(batch_size = BATCH_SIZE)\n",
        "val_set_15 = val_set_15.prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "test_set_15 = test_set\n",
        "test_set_15 = test_set_15.batch(batch_size = BATCH_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Teste 23: model 3 dataset 15 -> Accuracy 99.16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_3_15 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "model_3_15.load_weights('./cp.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path_3_15, callbacks_3_15 = prepareCallbacks('best_3_15')\n",
        "history_3_15 = model_3_15.fit(train_set_15,\n",
        "                              epochs = 50,\n",
        "                              validation_data = val_set_15,\n",
        "                              callbacks = callbacks_3_15,\n",
        "                              verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_3_15 = model_3_15.evaluate(test_set_15, verbose=2)\n",
        "print(eval_3_15)\n",
        "\n",
        "val_3_15 = model_3_15.evaluate(val_set_15, verbose=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TgaQAne4Afce"
      },
      "source": [
        "# Ensembles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16IYpEqRAiko"
      },
      "outputs": [],
      "source": [
        "# models\n",
        "model_1 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "model_2 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "model_3 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "model_4 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "model_5 = model_III(CLASS_COUNT, IMAGE_SIZE, 3)\n",
        "\n",
        "# load model weights\n",
        "model_1.load_weights('./model_1/cp.ckpt') # model_3_10 - 99.44\n",
        "model_2.load_weights('./model_2/cp.ckpt') # model_3_11 - 99.22\n",
        "model_3.load_weights('./model_3/cp.ckpt') # model_3_13 - 99.38\n",
        "model_4.load_weights('./model_4/cp.ckpt') # model_3_14 - 99.26\n",
        "model_5.load_weights('./model_5/cp.ckpt') # model_3_15 - 99.16\n",
        "\n",
        "# get list of models\n",
        "models = [model_1, model_2, model_3, model_4, model_5]\n",
        "\n",
        "input = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name='input') # input layer\n",
        "\n",
        "# get output for each model input\n",
        "outputs = [model(input) for model in models]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t6zwh5S-SLIA"
      },
      "source": [
        "# Concatenation Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ6Ch0nhSLIA"
      },
      "outputs": [],
      "source": [
        "# contenate the ouputs\n",
        "x = Concatenate()(outputs)\n",
        "\n",
        "# add further layers\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(CLASS_COUNT, activation='softmax', name='output')(x) # output layer\n",
        "\n",
        "# create concatenated model\n",
        "conc_model = Model(input, output, name='Concatenated_Model')\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "conc_model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# conc_model.load_weights('./drive/MyDrive/cp.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "-o9SNNn7SLIA",
        "outputId": "fd43fc9a-03bc-4a95-bbbe-5e0af29af53f"
      },
      "outputs": [],
      "source": [
        "plot_model(conc_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aSDx_7ryWs0Y",
        "outputId": "79f1ae6c-b396-4aa3-8bb6-60cbb5370d74"
      },
      "outputs": [],
      "source": [
        "file_path_conc_model, callbacks_conc_model = prepareCallbacks('conc_model')\n",
        "\n",
        "history_conc_model = conc_model.fit(train_set_10,\n",
        "                                    epochs = 60,\n",
        "                                    validation_data = val_set_10,\n",
        "                                    callbacks = callbacks_conc_model,\n",
        "                                    verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfbxGHVVW3rx",
        "outputId": "3d507fdd-266f-48f2-89a7-23b4bb50486e"
      },
      "outputs": [],
      "source": [
        "eval_conc_model = conc_model.evaluate(test_set_10, verbose=2)\n",
        "print(eval_conc_model)\n",
        "\n",
        "val_conc_model = conc_model.evaluate(val_set_10, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lvLeZkdN_7nl",
        "outputId": "b5ee4455-164a-4e17-f319-e7e9114a5762"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_10.take(-1):\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = conc_model.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qIvbqHWOAAyT"
      },
      "source": [
        "# Average Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olCo8-5AAE1P",
        "outputId": "38d5bdd4-e6a8-4b24-ee67-2929507b56bf"
      },
      "outputs": [],
      "source": [
        "# take average of the outputs\n",
        "output = Average()(outputs) # output layer\n",
        "\n",
        "# create average ensembled model\n",
        "avg_model = Model(input, output)\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "avg_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "avg_model.load_weights('./drive/MyDrive/cp.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "mfoobZnpCXSV",
        "outputId": "5740e116-b3af-4cea-eaed-1eaecc44d032"
      },
      "outputs": [],
      "source": [
        "plot_model(avg_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW7iNRM8CZK6",
        "outputId": "4261a7c6-a5dd-4efe-c43a-51f2722cb277"
      },
      "outputs": [],
      "source": [
        "file_path_avg_model, callbacks_avg_model = prepareCallbacks('avg_model')\n",
        "\n",
        "history_avg_model = avg_model.fit(train_set_10,\n",
        "                                  epochs = 60,\n",
        "                                  validation_data = val_set_10,\n",
        "                                  callbacks = callbacks_avg_model,\n",
        "                                  verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DRXR-0rvyU5",
        "outputId": "4730f4ea-c51c-4a34-dddb-ab8d668e55bb"
      },
      "outputs": [],
      "source": [
        "eval_avg_model = avg_model.evaluate(test_set_10, verbose=2)\n",
        "print(eval_avg_model)\n",
        "\n",
        "val_avg_model = avg_model.evaluate(val_set_10, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RJtCn3iiv8W3",
        "outputId": "1aed2165-bd21-4085-8951-b3047eb1fd8f"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_10.take(-1):\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = avg_model.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PR0sPnKR8cZh"
      },
      "source": [
        "# Weighted Average Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnaCDbJF8cZh"
      },
      "outputs": [],
      "source": [
        "# function for setting weights\n",
        "def weight_init(shape =(1,1,5), weights=[0.3,0.15,0.28,0.17,0.1], dtype=tf.float32):\n",
        "    return tf.constant(np.array(weights).reshape(shape), dtype=dtype)\n",
        "\n",
        "\n",
        "# custom weighted average layer\n",
        "class WeightedAverage(Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(WeightedAverage, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.W = self.add_weight(name=\"weight_layer\",\n",
        "                    shape=(1,1,len(input_shape)),\n",
        "                    initializer=weight_init,\n",
        "                    dtype=tf.float32,\n",
        "                    trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        inputs = [tf.expand_dims(i, -1) for i in inputs]\n",
        "        inputs = Concatenate(axis=-1)(inputs)\n",
        "        weights = tf.nn.softmax(self.W, axis=-1)\n",
        "\n",
        "        return tf.reduce_mean(weights*inputs, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlkfQ2C48cZh",
        "outputId": "64f7149d-5c82-4bd1-9db2-e648c1534e30"
      },
      "outputs": [],
      "source": [
        "# take weighted average of the outputs\n",
        "output = WeightedAverage()(outputs) # output layer\n",
        "\n",
        "# create average ensembled model\n",
        "weighted_avg_model = Model(input, output)\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "weighted_avg_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "weighted_avg_model.load_weights('./drive/MyDrive/cp.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoAOmrrV8cZh"
      },
      "outputs": [],
      "source": [
        "plot_model(weighted_avg_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUMSGSEh8cZi",
        "outputId": "dae67fee-8a4d-41b9-9e1d-a089073ec2c6"
      },
      "outputs": [],
      "source": [
        "file_path_weighted_avg_model, callbacks_weighted_avg_model = prepareCallbacks('weighted_avg_model')\n",
        "\n",
        "history_weighted_avg_model = weighted_avg_model.fit(train_set_10,\n",
        "                                                    epochs = 60,\n",
        "                                                    validation_data = val_set_10,\n",
        "                                                    callbacks = callbacks_weighted_avg_model,\n",
        "                                                    verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGnQUf3i8cZi",
        "outputId": "aa665297-e4fe-4a9c-ac24-58ae3cb393f0"
      },
      "outputs": [],
      "source": [
        "eval_weighted_avg_model = weighted_avg_model.evaluate(test_set_10, verbose=2)\n",
        "print(eval_weighted_avg_model)\n",
        "\n",
        "val_weighted_avg_model = weighted_avg_model.evaluate(val_set_10, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ipWSJDMYWd30",
        "outputId": "b03d059b-8ba4-4336-b852-499aed8268ae"
      },
      "outputs": [],
      "source": [
        "for images, labels in test_set_10.take(-1):\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "\n",
        "    preds = weighted_avg_model.predict(numpy_images)\n",
        "    show_misclassified(preds, numpy_labels, numpy_images, 5, 3)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_HG2o62RXaar",
        "R1knVrr1oJvk",
        "lxsaa0_RXaay",
        "UFhO0VIPXaa0",
        "7V-Jd6_FXaa1",
        "SjZx4InJKEwC",
        "n5ef5buDsgDi",
        "PE6fwqPCcWUL",
        "mMQjmZU4wrC3",
        "UcEZlkdPsCDN",
        "OLGpQIsXcWUM",
        "n_8SuRV9bihM",
        "n2LDofMDrRof",
        "KyB2rGqzf1Xg",
        "sKaZSsoLcWUS",
        "qim2MvFqcWUU",
        "z5ILSWqfZ0H6",
        "9NAxlCbeH5-w",
        "OC17zmzQH5-x",
        "MkZ_clL1kkfG",
        "lW_oiA_olPtB",
        "SADKJXcLlmjx",
        "ugKmv3gUlZXb",
        "D89YamoFH5-z",
        "yKvS6S2zH5-0",
        "A9tjiKUrY-gz",
        "rOqM-3SzAzPa",
        "TH_A5HVpmyaX",
        "TTbFkH5yn1Bc",
        "Qa-5MXsncWUd",
        "SpJgxBOVokTf",
        "WjfMMi5hJf-r",
        "Ji89wulccWUl",
        "UWBzYDY_JrGn",
        "xyJH5_6ZcWUp",
        "q_zmNvjhp3Bi",
        "8irDiSa0zF5e",
        "tI8I7dA-Xkh2",
        "umGtUbk3Z81j",
        "vpFd3EF8_kPI",
        "WbwLBv-frzsq",
        "vDmNcArbtnWJ",
        "26HMvLjZtsWT",
        "GTJjqcMoz4D5"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
